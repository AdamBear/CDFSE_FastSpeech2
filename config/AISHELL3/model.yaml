transformer:
  encoder_layer: 4
  encoder_head: 2
  encoder_hidden: 256
  decoder_layer: 6
  decoder_head: 2
  decoder_hidden: 256
  conv_filter_size: 1024
  conv_kernel_size: [9, 1]
  encoder_dropout: 0.2
  decoder_dropout: 0.2

variance_predictor:
  filter_size: 256
  kernel_size: 3
  dropout: 0.5

variance_embedding:
  pitch_quantization: "linear" # support 'linear' or 'log', 'log' is allowed only if the pitch values are not normalized during preprocessing
  energy_quantization: "linear" # support 'linear' or 'log', 'log' is allowed only if the energy values are not normalized during preprocessing
  n_bins: 256

classifier:  
  cls_hidden: []

frame_encoder:
  conv_filters: [512, 512]
  stride: 1
  kernel_size: 5
  padding: 2
  dropout: 0.5
  out_dim: 256

downsample_encoder:
  conv_filters: [128, 256, 512, 512]
  kernel_size: 3
  stride: 1
  padding: 1
  pooling_sizes: [2, 2, 2, 2]
  dropout: 0.2
  out_dim: 256

bpt:
  num_tokens: 40
  token_embed_dim: 256
  num_heads: 1

reference_attention:
  key_dim: 256
  attention_dim: 128
  attention_dropout: 0.0

use_BPT: False
use_spkcls: True

weight:
  cls: 1.0

max_seq_len: 2000

vocoder:
  model: "HiFi-GAN" # support 'HiFi-GAN', 'MelGAN'
  speaker: "AISHELL3_22k" # support  'LJSpeech', 'universal'
